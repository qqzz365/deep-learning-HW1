{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faac4da6",
   "metadata": {},
   "source": [
    "## ResNet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47d1cace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc223050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class ImageNetMiniDataset(Dataset):\n",
    "    def __init__(self, txt_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        txt_file: .txt 檔案路徑（例如 train.txt）\n",
    "        root_dir: 圖像資料夾根目錄（例如 .）\n",
    "        transform: 圖像預處理變換\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        # 讀取 .txt 檔案，存儲圖像路徑和標籤\n",
    "        self.data = []\n",
    "        with open(txt_file, 'r') as f:\n",
    "            for line in f:\n",
    "                image_path, label = line.strip().split()\n",
    "                self.data.append((image_path, int(label)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path, label = self.data[idx]\n",
    "        # 拼接完整圖像路徑\n",
    "        image_path = os.path.join(self.root_dir, image_path)\n",
    "        # 讀取圖像\n",
    "        image = Image.open(image_path).convert('RGB')  # 轉為 RGB 格式\n",
    "        # 應用變換（如果有）\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbb7ef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 定義圖像預處理（ResNet 標準預處理）\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # 調整大小為 224x224\n",
    "    transforms.ToTensor(),  # 轉為 Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet 均值\n",
    "                        std=[0.229, 0.224, 0.225])  # ImageNet 標準差\n",
    "])\n",
    "\n",
    "# 加載數據集\n",
    "extract_path = \"dataset\"\n",
    "train_dataset = ImageNetMiniDataset(txt_file=\"dataset/train.txt\", root_dir=extract_path, transform=transform)\n",
    "val_dataset = ImageNetMiniDataset(txt_file=\"dataset/val.txt\", root_dir=extract_path, transform=transform)\n",
    "test_dataset = ImageNetMiniDataset(txt_file=\"dataset/test.txt\", root_dir=extract_path, transform=transform)\n",
    "\n",
    "# 創建 DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1db2ebbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "# 定義 ResNet34 對照組模型（不修改任何結構）\n",
    "class ResNet34Baseline(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(ResNet34Baseline, self).__init__()\n",
    "        # 直接載入 torchvision 中的 ResNet34 模型，不使用預訓練權重\n",
    "        self.model = models.resnet34(pretrained=False)\n",
    "        # 確認全連接層的輸出類別數（ImageNet 為 1000 類）\n",
    "        # ResNet34 的全連接層預設已經適配 1000 類，因此這裡不需要修改\n",
    "        # 如果 num_classes 不等於 1000，可以替換全連接層如下：\n",
    "        if num_classes != 1000:\n",
    "            self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# 測試模型\n",
    "def test_model():\n",
    "    # 創建模型實例\n",
    "    model = ResNet34Baseline(num_classes=1000)\n",
    "    # 模擬輸入：批次大小 4，3 通道，224x224 圖像\n",
    "    x = torch.randn(4, 3, 224, 224)\n",
    "    # 前向傳播\n",
    "    output = model(x)\n",
    "    print(f\"輸出形狀：{output.shape}\")  # 應為 (4, 1000)\n",
    "    # 計算參數量\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"模型總參數量：{total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17d7535d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型總參數量：21310322\n",
      "Epoch [1/10] 訓練損失：3.2980 訓練準確率：12.66%\n",
      "驗證準確率：17.56%\n",
      "Epoch [2/10] 訓練損失：2.6552 訓練準確率：25.41%\n",
      "驗證準確率：28.44%\n",
      "Epoch [3/10] 訓練損失：2.1607 訓練準確率：37.02%\n",
      "驗證準確率：38.22%\n",
      "Epoch [4/10] 訓練損失：1.7826 訓練準確率：46.44%\n",
      "驗證準確率：45.56%\n",
      "Epoch [5/10] 訓練損失：1.4888 訓練準確率：54.41%\n",
      "驗證準確率：53.11%\n",
      "Epoch [6/10] 訓練損失：1.2480 訓練準確率：60.93%\n",
      "驗證準確率：54.00%\n",
      "Epoch [7/10] 訓練損失：1.0300 訓練準確率：67.11%\n",
      "驗證準確率：57.33%\n",
      "Epoch [8/10] 訓練損失：0.8115 訓練準確率：73.26%\n",
      "驗證準確率：59.78%\n",
      "Epoch [9/10] 訓練損失：0.6140 訓練準確率：79.22%\n",
      "驗證準確率：64.00%\n",
      "Epoch [10/10] 訓練損失：0.4525 訓練準確率：84.46%\n",
      "驗證準確率：61.56%\n",
      "測試準確率：60.44%\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 42, 42]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 42, 42]             128\n",
      "              ReLU-3           [-1, 64, 42, 42]               0\n",
      "         MaxPool2d-4           [-1, 64, 21, 21]               0\n",
      "            Conv2d-5           [-1, 64, 21, 21]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 21, 21]             128\n",
      "              ReLU-7           [-1, 64, 21, 21]               0\n",
      "            Conv2d-8           [-1, 64, 21, 21]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 21, 21]             128\n",
      "             ReLU-10           [-1, 64, 21, 21]               0\n",
      "       BasicBlock-11           [-1, 64, 21, 21]               0\n",
      "           Conv2d-12           [-1, 64, 21, 21]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 21, 21]             128\n",
      "             ReLU-14           [-1, 64, 21, 21]               0\n",
      "           Conv2d-15           [-1, 64, 21, 21]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 21, 21]             128\n",
      "             ReLU-17           [-1, 64, 21, 21]               0\n",
      "       BasicBlock-18           [-1, 64, 21, 21]               0\n",
      "           Conv2d-19           [-1, 64, 21, 21]          36,864\n",
      "      BatchNorm2d-20           [-1, 64, 21, 21]             128\n",
      "             ReLU-21           [-1, 64, 21, 21]               0\n",
      "           Conv2d-22           [-1, 64, 21, 21]          36,864\n",
      "      BatchNorm2d-23           [-1, 64, 21, 21]             128\n",
      "             ReLU-24           [-1, 64, 21, 21]               0\n",
      "       BasicBlock-25           [-1, 64, 21, 21]               0\n",
      "           Conv2d-26          [-1, 128, 11, 11]          73,728\n",
      "      BatchNorm2d-27          [-1, 128, 11, 11]             256\n",
      "             ReLU-28          [-1, 128, 11, 11]               0\n",
      "           Conv2d-29          [-1, 128, 11, 11]         147,456\n",
      "      BatchNorm2d-30          [-1, 128, 11, 11]             256\n",
      "           Conv2d-31          [-1, 128, 11, 11]           8,192\n",
      "      BatchNorm2d-32          [-1, 128, 11, 11]             256\n",
      "             ReLU-33          [-1, 128, 11, 11]               0\n",
      "       BasicBlock-34          [-1, 128, 11, 11]               0\n",
      "           Conv2d-35          [-1, 128, 11, 11]         147,456\n",
      "      BatchNorm2d-36          [-1, 128, 11, 11]             256\n",
      "             ReLU-37          [-1, 128, 11, 11]               0\n",
      "           Conv2d-38          [-1, 128, 11, 11]         147,456\n",
      "      BatchNorm2d-39          [-1, 128, 11, 11]             256\n",
      "             ReLU-40          [-1, 128, 11, 11]               0\n",
      "       BasicBlock-41          [-1, 128, 11, 11]               0\n",
      "           Conv2d-42          [-1, 128, 11, 11]         147,456\n",
      "      BatchNorm2d-43          [-1, 128, 11, 11]             256\n",
      "             ReLU-44          [-1, 128, 11, 11]               0\n",
      "           Conv2d-45          [-1, 128, 11, 11]         147,456\n",
      "      BatchNorm2d-46          [-1, 128, 11, 11]             256\n",
      "             ReLU-47          [-1, 128, 11, 11]               0\n",
      "       BasicBlock-48          [-1, 128, 11, 11]               0\n",
      "           Conv2d-49          [-1, 128, 11, 11]         147,456\n",
      "      BatchNorm2d-50          [-1, 128, 11, 11]             256\n",
      "             ReLU-51          [-1, 128, 11, 11]               0\n",
      "           Conv2d-52          [-1, 128, 11, 11]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 11, 11]             256\n",
      "             ReLU-54          [-1, 128, 11, 11]               0\n",
      "       BasicBlock-55          [-1, 128, 11, 11]               0\n",
      "           Conv2d-56            [-1, 256, 6, 6]         294,912\n",
      "      BatchNorm2d-57            [-1, 256, 6, 6]             512\n",
      "             ReLU-58            [-1, 256, 6, 6]               0\n",
      "           Conv2d-59            [-1, 256, 6, 6]         589,824\n",
      "      BatchNorm2d-60            [-1, 256, 6, 6]             512\n",
      "           Conv2d-61            [-1, 256, 6, 6]          32,768\n",
      "      BatchNorm2d-62            [-1, 256, 6, 6]             512\n",
      "             ReLU-63            [-1, 256, 6, 6]               0\n",
      "       BasicBlock-64            [-1, 256, 6, 6]               0\n",
      "           Conv2d-65            [-1, 256, 6, 6]         589,824\n",
      "      BatchNorm2d-66            [-1, 256, 6, 6]             512\n",
      "             ReLU-67            [-1, 256, 6, 6]               0\n",
      "           Conv2d-68            [-1, 256, 6, 6]         589,824\n",
      "      BatchNorm2d-69            [-1, 256, 6, 6]             512\n",
      "             ReLU-70            [-1, 256, 6, 6]               0\n",
      "       BasicBlock-71            [-1, 256, 6, 6]               0\n",
      "           Conv2d-72            [-1, 256, 6, 6]         589,824\n",
      "      BatchNorm2d-73            [-1, 256, 6, 6]             512\n",
      "             ReLU-74            [-1, 256, 6, 6]               0\n",
      "           Conv2d-75            [-1, 256, 6, 6]         589,824\n",
      "      BatchNorm2d-76            [-1, 256, 6, 6]             512\n",
      "             ReLU-77            [-1, 256, 6, 6]               0\n",
      "       BasicBlock-78            [-1, 256, 6, 6]               0\n",
      "           Conv2d-79            [-1, 256, 6, 6]         589,824\n",
      "      BatchNorm2d-80            [-1, 256, 6, 6]             512\n",
      "             ReLU-81            [-1, 256, 6, 6]               0\n",
      "           Conv2d-82            [-1, 256, 6, 6]         589,824\n",
      "      BatchNorm2d-83            [-1, 256, 6, 6]             512\n",
      "             ReLU-84            [-1, 256, 6, 6]               0\n",
      "       BasicBlock-85            [-1, 256, 6, 6]               0\n",
      "           Conv2d-86            [-1, 256, 6, 6]         589,824\n",
      "      BatchNorm2d-87            [-1, 256, 6, 6]             512\n",
      "             ReLU-88            [-1, 256, 6, 6]               0\n",
      "           Conv2d-89            [-1, 256, 6, 6]         589,824\n",
      "      BatchNorm2d-90            [-1, 256, 6, 6]             512\n",
      "             ReLU-91            [-1, 256, 6, 6]               0\n",
      "       BasicBlock-92            [-1, 256, 6, 6]               0\n",
      "           Conv2d-93            [-1, 256, 6, 6]         589,824\n",
      "      BatchNorm2d-94            [-1, 256, 6, 6]             512\n",
      "             ReLU-95            [-1, 256, 6, 6]               0\n",
      "           Conv2d-96            [-1, 256, 6, 6]         589,824\n",
      "      BatchNorm2d-97            [-1, 256, 6, 6]             512\n",
      "             ReLU-98            [-1, 256, 6, 6]               0\n",
      "       BasicBlock-99            [-1, 256, 6, 6]               0\n",
      "          Conv2d-100            [-1, 512, 3, 3]       1,179,648\n",
      "     BatchNorm2d-101            [-1, 512, 3, 3]           1,024\n",
      "            ReLU-102            [-1, 512, 3, 3]               0\n",
      "          Conv2d-103            [-1, 512, 3, 3]       2,359,296\n",
      "     BatchNorm2d-104            [-1, 512, 3, 3]           1,024\n",
      "          Conv2d-105            [-1, 512, 3, 3]         131,072\n",
      "     BatchNorm2d-106            [-1, 512, 3, 3]           1,024\n",
      "            ReLU-107            [-1, 512, 3, 3]               0\n",
      "      BasicBlock-108            [-1, 512, 3, 3]               0\n",
      "          Conv2d-109            [-1, 512, 3, 3]       2,359,296\n",
      "     BatchNorm2d-110            [-1, 512, 3, 3]           1,024\n",
      "            ReLU-111            [-1, 512, 3, 3]               0\n",
      "          Conv2d-112            [-1, 512, 3, 3]       2,359,296\n",
      "     BatchNorm2d-113            [-1, 512, 3, 3]           1,024\n",
      "            ReLU-114            [-1, 512, 3, 3]               0\n",
      "      BasicBlock-115            [-1, 512, 3, 3]               0\n",
      "          Conv2d-116            [-1, 512, 3, 3]       2,359,296\n",
      "     BatchNorm2d-117            [-1, 512, 3, 3]           1,024\n",
      "            ReLU-118            [-1, 512, 3, 3]               0\n",
      "          Conv2d-119            [-1, 512, 3, 3]       2,359,296\n",
      "     BatchNorm2d-120            [-1, 512, 3, 3]           1,024\n",
      "            ReLU-121            [-1, 512, 3, 3]               0\n",
      "      BasicBlock-122            [-1, 512, 3, 3]               0\n",
      "AdaptiveAvgPool2d-123            [-1, 512, 1, 1]               0\n",
      "          Linear-124                   [-1, 50]          25,650\n",
      "          ResNet-125                   [-1, 50]               0\n",
      "================================================================\n",
      "Total params: 21,310,322\n",
      "Trainable params: 21,310,322\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.08\n",
      "Forward/backward pass size (MB): 14.77\n",
      "Params size (MB): 81.29\n",
      "Estimated Total Size (MB): 96.15\n",
      "----------------------------------------------------------------\n",
      "Computational complexity: 614.77 MMac\n",
      "Number of parameters: 21.31 M\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "from torchsummary import summary\n",
    "\n",
    "def main():\n",
    "    num_classes = 50\n",
    "\n",
    "    # 初始化模型\n",
    "    model = ResNet34Baseline(num_classes=num_classes).to(device)\n",
    "    print(f\"模型總參數量：{sum(p.numel() for p in model.parameters())}\")\n",
    "\n",
    "    # 定義損失函數和優化器\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # 訓練迴圈\n",
    "    num_epochs = 10  # 訓練 10 個 epoch（可調整）\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # 前向傳播\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # 反向傳播和優化\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # 計算損失和準確率\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = 100 * correct / total\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] 訓練損失：{epoch_loss:.4f} 訓練準確率：{epoch_acc:.2f}%\")\n",
    "\n",
    "        # 驗證階段\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        print(f\"驗證準確率：{val_acc:.2f}%\")\n",
    "\n",
    "    # 測試階段\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_acc = 100 * test_correct / test_total\n",
    "    print(f\"測試準確率：{test_acc:.2f}%\")\n",
    "\n",
    "    summary(model, (3, 84, 84))  # 假設輸入是 RGB 圖像\n",
    "\n",
    "    # 如果需要計算 FLOPS，可以使用 ptflops\n",
    "    try:\n",
    "        from ptflops import get_model_complexity_info\n",
    "        flops, params = get_model_complexity_info(model, (3, 84, 84), as_strings=True, print_per_layer_stat=False)\n",
    "        print(f\"Computational complexity: {flops}\")\n",
    "        print(f\"Number of parameters: {params}\")\n",
    "    except ImportError:\n",
    "        print(\"Please install ptflops to compute FLOPS: pip install ptflops\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdcece5",
   "metadata": {},
   "source": [
    "## MyNet: SimpleResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d589130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 定義基本的殘差塊\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        # 第一個卷積層，可能改變空間尺寸（通過 stride）\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        # 第二個卷積層，保持尺寸不變\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # 殘差連接：如果輸入輸出通道數或尺寸不匹配，則用 1x1 卷積調整\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        # 殘差連接：將輸入（經過調整）與輸出相加\n",
    "        out += self.shortcut(identity)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "# 定義簡化的 ResNet 模型\n",
    "class SimpleResNet(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(SimpleResNet, self).__init__()\n",
    "        # 初始卷積層：7x7 卷積，64 個濾波器，步幅 2\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        # 最大池化層：3x3，步幅 2\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # 殘差塊 1：輸入 64 通道，輸出 64 通道，步幅 1\n",
    "        self.block1 = ResidualBlock(64, 64, stride=1)\n",
    "        # 殘差塊 2：輸入 64 通道，輸出 128 通道，步幅 2（降採樣）\n",
    "        self.block2 = ResidualBlock(64, 128, stride=2)\n",
    "\n",
    "        # 全局平均池化\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        # 全連接層：128 通道到分類數量\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 初始卷積和池化\n",
    "        x = self.conv1(x)  # 輸入：224x224x3，輸出：112x112x64\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)  # 輸出：56x56x64\n",
    "\n",
    "        # 殘差塊\n",
    "        x = self.block1(x)  # 輸出：56x56x64\n",
    "        x = self.block2(x)  # 輸出：28x28x128\n",
    "\n",
    "        # 全局平均池化和全連接層\n",
    "        x = self.avgpool(x)  # 輸出：1x1x128\n",
    "        x = torch.flatten(x, 1)  # 展平為 (batch_size, 128)\n",
    "        x = self.fc(x)  # 輸出：(batch_size, num_classes)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4fb0851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輸出形狀：torch.Size([4, 50])\n",
      "模型總參數量：320114\n"
     ]
    }
   ],
   "source": [
    "# 測試模型\n",
    "def test_model():\n",
    "    # 創建模型實例\n",
    "    model = SimpleResNet(num_classes=50)\n",
    "    # 模擬輸入：批次大小 4，3 通道，224x224 圖像\n",
    "    x = torch.randn(4, 3, 224, 224)\n",
    "    # 前向傳播\n",
    "    output = model(x)\n",
    "    print(f\"輸出形狀：{output.shape}\")  # 應為 (4, 1000)\n",
    "    # 計算參數量\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"模型總參數量：{total_params}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b690f93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型總參數量：320114\n",
      "Epoch [1/20] 訓練損失：3.3739 訓練準確率：12.71%\n",
      "驗證準確率：14.44%\n",
      "Epoch [2/20] 訓練損失：2.9674 訓練準確率：20.63%\n",
      "驗證準確率：22.00%\n",
      "Epoch [3/20] 訓練損失：2.6523 訓練準確率：27.28%\n",
      "驗證準確率：25.33%\n",
      "Epoch [4/20] 訓練損失：2.4323 訓練準確率：32.13%\n",
      "驗證準確率：32.89%\n",
      "Epoch [5/20] 訓練損失：2.2757 訓練準確率：35.89%\n",
      "驗證準確率：30.00%\n",
      "Epoch [6/20] 訓練損失：2.1553 訓練準確率：38.63%\n",
      "驗證準確率：38.89%\n",
      "Epoch [7/20] 訓練損失：2.0509 訓練準確率：41.14%\n",
      "驗證準確率：40.22%\n",
      "Epoch [8/20] 訓練損失：1.9589 訓練準確率：43.38%\n",
      "驗證準確率：39.33%\n",
      "Epoch [9/20] 訓練損失：1.8814 訓練準確率：45.69%\n",
      "驗證準確率：41.11%\n",
      "Epoch [10/20] 訓練損失：1.8032 訓練準確率：47.66%\n",
      "驗證準確率：46.67%\n",
      "Epoch [11/20] 訓練損失：1.7382 訓練準確率：49.35%\n",
      "驗證準確率：47.11%\n",
      "Epoch [12/20] 訓練損失：1.6827 訓練準確率：50.81%\n",
      "驗證準確率：47.78%\n",
      "Epoch [13/20] 訓練損失：1.6278 訓練準確率：52.39%\n",
      "驗證準確率：48.44%\n",
      "Epoch [14/20] 訓練損失：1.5771 訓練準確率：53.63%\n",
      "驗證準確率：49.56%\n",
      "Epoch [15/20] 訓練損失：1.5296 訓練準確率：54.91%\n",
      "驗證準確率：51.78%\n",
      "Epoch [16/20] 訓練損失：1.4917 訓練準確率：55.74%\n",
      "驗證準確率：51.56%\n",
      "Epoch [17/20] 訓練損失：1.4535 訓練準確率：56.96%\n",
      "驗證準確率：51.33%\n",
      "Epoch [18/20] 訓練損失：1.4178 訓練準確率：57.79%\n",
      "驗證準確率：55.33%\n",
      "Epoch [19/20] 訓練損失：1.3752 訓練準確率：59.16%\n",
      "驗證準確率：56.67%\n",
      "Epoch [20/20] 訓練損失：1.3427 訓練準確率：59.85%\n",
      "驗證準確率：55.78%\n",
      "測試準確率：57.78%\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 42, 42]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 42, 42]             128\n",
      "              ReLU-3           [-1, 64, 42, 42]               0\n",
      "         MaxPool2d-4           [-1, 64, 21, 21]               0\n",
      "            Conv2d-5           [-1, 64, 21, 21]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 21, 21]             128\n",
      "              ReLU-7           [-1, 64, 21, 21]               0\n",
      "            Conv2d-8           [-1, 64, 21, 21]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 21, 21]             128\n",
      "             ReLU-10           [-1, 64, 21, 21]               0\n",
      "    ResidualBlock-11           [-1, 64, 21, 21]               0\n",
      "           Conv2d-12          [-1, 128, 11, 11]          73,728\n",
      "      BatchNorm2d-13          [-1, 128, 11, 11]             256\n",
      "             ReLU-14          [-1, 128, 11, 11]               0\n",
      "           Conv2d-15          [-1, 128, 11, 11]         147,456\n",
      "      BatchNorm2d-16          [-1, 128, 11, 11]             256\n",
      "           Conv2d-17          [-1, 128, 11, 11]           8,192\n",
      "      BatchNorm2d-18          [-1, 128, 11, 11]             256\n",
      "             ReLU-19          [-1, 128, 11, 11]               0\n",
      "    ResidualBlock-20          [-1, 128, 11, 11]               0\n",
      "AdaptiveAvgPool2d-21            [-1, 128, 1, 1]               0\n",
      "           Linear-22                   [-1, 50]           6,450\n",
      "================================================================\n",
      "Total params: 320,114\n",
      "Trainable params: 320,114\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.08\n",
      "Forward/backward pass size (MB): 5.37\n",
      "Params size (MB): 1.22\n",
      "Estimated Total Size (MB): 6.67\n",
      "----------------------------------------------------------------\n",
      "Computational complexity: 77.96 MMac\n",
      "Number of parameters: 320.11 k\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "def main():\n",
    "    num_classes = 50\n",
    "\n",
    "    # 初始化模型\n",
    "    model = SimpleResNet(num_classes=num_classes).to(device)\n",
    "    print(f\"模型總參數量：{sum(p.numel() for p in model.parameters())}\")\n",
    "\n",
    "    # 定義損失函數和優化器\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # 訓練迴圈\n",
    "    num_epochs = 20  # 訓練 10 個 epoch（可調整）\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # 前向傳播\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # 反向傳播和優化\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # 計算損失和準確率\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = 100 * correct / total\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] 訓練損失：{epoch_loss:.4f} 訓練準確率：{epoch_acc:.2f}%\")\n",
    "\n",
    "        # 驗證階段\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        print(f\"驗證準確率：{val_acc:.2f}%\")\n",
    "\n",
    "    # 測試階段\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_acc = 100 * test_correct / test_total\n",
    "    print(f\"測試準確率：{test_acc:.2f}%\")\n",
    "\n",
    "    summary(model, (3, 84, 84))  # 假設輸入是 RGB 圖像\n",
    "\n",
    "    # 如果需要計算 FLOPS，可以使用 ptflops\n",
    "    try:\n",
    "        from ptflops import get_model_complexity_info\n",
    "        flops, params = get_model_complexity_info(model, (3, 84, 84), as_strings=True, print_per_layer_stat=False)\n",
    "        print(f\"Computational complexity: {flops}\")\n",
    "        print(f\"Number of parameters: {params}\")\n",
    "    except ImportError:\n",
    "        print(\"Please install ptflops to compute FLOPS: pip install ptflops\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184362b7",
   "metadata": {},
   "source": [
    "## 消融實驗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6592326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Experiment: No_Shortcut ===\n",
      "Train Epoch: 1, Loss: 3.4925, Accuracy: 10.66%\n",
      "Validation Loss: 3.2399, Accuracy: 12.00%\n",
      "Train Epoch: 2, Loss: 3.2325, Accuracy: 15.61%\n",
      "Validation Loss: 3.1421, Accuracy: 13.33%\n",
      "Train Epoch: 3, Loss: 3.0432, Accuracy: 19.36%\n",
      "Validation Loss: 2.9441, Accuracy: 16.89%\n",
      "Train Epoch: 4, Loss: 2.9040, Accuracy: 22.28%\n",
      "Validation Loss: 2.7958, Accuracy: 22.44%\n",
      "Train Epoch: 5, Loss: 2.7971, Accuracy: 24.67%\n",
      "Validation Loss: 2.6693, Accuracy: 24.89%\n",
      "Train Epoch: 6, Loss: 2.7083, Accuracy: 26.44%\n",
      "Validation Loss: 2.7531, Accuracy: 20.67%\n",
      "Train Epoch: 7, Loss: 2.6359, Accuracy: 28.11%\n",
      "Validation Loss: 2.6102, Accuracy: 26.00%\n",
      "Train Epoch: 8, Loss: 2.5719, Accuracy: 29.67%\n",
      "Validation Loss: 2.5026, Accuracy: 26.22%\n",
      "Train Epoch: 9, Loss: 2.5206, Accuracy: 30.75%\n",
      "Validation Loss: 2.5405, Accuracy: 28.67%\n",
      "Train Epoch: 10, Loss: 2.4753, Accuracy: 31.40%\n",
      "Validation Loss: 2.4529, Accuracy: 29.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2444808/2043843109.py:202: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 33.56%\n",
      "FLOPs: 0.05 GFLOPs, Parameters: 0.09 M\n",
      "\n",
      "=== Running Experiment: No_MaxPool ===\n",
      "Train Epoch: 1, Loss: 3.5490, Accuracy: 9.53%\n",
      "Validation Loss: 3.3288, Accuracy: 13.11%\n",
      "Train Epoch: 2, Loss: 3.3627, Accuracy: 12.88%\n",
      "Validation Loss: 3.2386, Accuracy: 13.11%\n",
      "Train Epoch: 3, Loss: 3.2431, Accuracy: 15.38%\n",
      "Validation Loss: 3.1593, Accuracy: 14.22%\n",
      "Train Epoch: 4, Loss: 3.1366, Accuracy: 17.66%\n",
      "Validation Loss: 2.9981, Accuracy: 16.44%\n",
      "Train Epoch: 5, Loss: 3.0502, Accuracy: 19.61%\n",
      "Validation Loss: 2.9576, Accuracy: 18.00%\n",
      "Train Epoch: 6, Loss: 2.9699, Accuracy: 21.50%\n",
      "Validation Loss: 2.8174, Accuracy: 20.89%\n",
      "Train Epoch: 7, Loss: 2.9093, Accuracy: 22.49%\n",
      "Validation Loss: 2.8711, Accuracy: 19.78%\n",
      "Train Epoch: 8, Loss: 2.8536, Accuracy: 23.87%\n",
      "Validation Loss: 2.7357, Accuracy: 24.22%\n",
      "Train Epoch: 9, Loss: 2.8006, Accuracy: 25.09%\n",
      "Validation Loss: 2.7178, Accuracy: 23.56%\n",
      "Train Epoch: 10, Loss: 2.7575, Accuracy: 25.92%\n",
      "Validation Loss: 2.9475, Accuracy: 21.56%\n",
      "Test Accuracy: 26.67%\n",
      "FLOPs: 0.15 GFLOPs, Parameters: 0.09 M\n",
      "\n",
      "=== Running Experiment: No_BatchNorm ===\n",
      "Train Epoch: 1, Loss: 3.5874, Accuracy: 8.64%\n",
      "Validation Loss: 3.3876, Accuracy: 10.67%\n",
      "Train Epoch: 2, Loss: 3.4430, Accuracy: 11.38%\n",
      "Validation Loss: 3.2714, Accuracy: 11.78%\n",
      "Train Epoch: 3, Loss: 3.3449, Accuracy: 13.29%\n",
      "Validation Loss: 3.1070, Accuracy: 14.89%\n",
      "Train Epoch: 4, Loss: 3.2457, Accuracy: 15.37%\n",
      "Validation Loss: 3.0912, Accuracy: 15.33%\n",
      "Train Epoch: 5, Loss: 3.1565, Accuracy: 17.16%\n",
      "Validation Loss: 2.9922, Accuracy: 18.00%\n",
      "Train Epoch: 6, Loss: 3.0741, Accuracy: 19.02%\n",
      "Validation Loss: 2.9778, Accuracy: 16.00%\n",
      "Train Epoch: 7, Loss: 2.9932, Accuracy: 20.92%\n",
      "Validation Loss: 2.8765, Accuracy: 19.11%\n",
      "Train Epoch: 8, Loss: 2.9285, Accuracy: 22.07%\n",
      "Validation Loss: 2.8187, Accuracy: 19.56%\n",
      "Train Epoch: 9, Loss: 2.8723, Accuracy: 23.54%\n",
      "Validation Loss: 2.7656, Accuracy: 21.56%\n",
      "Train Epoch: 10, Loss: 2.8209, Accuracy: 24.75%\n",
      "Validation Loss: 2.7516, Accuracy: 23.78%\n",
      "Test Accuracy: 27.78%\n",
      "FLOPs: 0.05 GFLOPs, Parameters: 0.09 M\n",
      "\n",
      "=== Running Experiment: Extra_Block ===\n",
      "Train Epoch: 1, Loss: 3.4580, Accuracy: 11.03%\n",
      "Validation Loss: 3.1798, Accuracy: 15.11%\n",
      "Train Epoch: 2, Loss: 3.1348, Accuracy: 17.40%\n",
      "Validation Loss: 3.0900, Accuracy: 16.89%\n",
      "Train Epoch: 3, Loss: 2.8755, Accuracy: 22.54%\n",
      "Validation Loss: 2.6765, Accuracy: 25.11%\n",
      "Train Epoch: 4, Loss: 2.6636, Accuracy: 27.28%\n",
      "Validation Loss: 2.7102, Accuracy: 28.89%\n",
      "Train Epoch: 5, Loss: 2.5125, Accuracy: 30.41%\n",
      "Validation Loss: 2.4729, Accuracy: 29.56%\n",
      "Train Epoch: 6, Loss: 2.3961, Accuracy: 32.86%\n",
      "Validation Loss: 2.2830, Accuracy: 32.44%\n",
      "Train Epoch: 7, Loss: 2.3044, Accuracy: 35.21%\n",
      "Validation Loss: 2.3166, Accuracy: 33.33%\n",
      "Train Epoch: 8, Loss: 2.2217, Accuracy: 37.11%\n",
      "Validation Loss: 2.2719, Accuracy: 32.67%\n",
      "Train Epoch: 9, Loss: 2.1580, Accuracy: 38.32%\n",
      "Validation Loss: 2.5538, Accuracy: 32.89%\n",
      "Train Epoch: 10, Loss: 2.0933, Accuracy: 40.12%\n",
      "Validation Loss: 2.0814, Accuracy: 39.33%\n",
      "Test Accuracy: 38.89%\n",
      "FLOPs: 0.08 GFLOPs, Parameters: 0.16 M\n",
      "\n",
      "=== Ablation Study Results ===\n",
      "No_Shortcut: Validation Accuracy = 29.78%, Test Accuracy = 33.56%, FLOPs = 0.05 GFLOPs, Parameters = 0.09 M\n",
      "No_MaxPool: Validation Accuracy = 24.22%, Test Accuracy = 26.67%, FLOPs = 0.15 GFLOPs, Parameters = 0.09 M\n",
      "No_BatchNorm: Validation Accuracy = 23.78%, Test Accuracy = 27.78%, FLOPs = 0.05 GFLOPs, Parameters = 0.09 M\n",
      "Extra_Block: Validation Accuracy = 39.33%, Test Accuracy = 38.89%, FLOPs = 0.08 GFLOPs, Parameters = 0.16 M\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from thop import profile  # 用於計算 FLOPs 和參數量\n",
    "import os\n",
    "\n",
    "# 定義 ResidualBlock（從你提供）\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += self.shortcut(identity)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "# 無 Shortcut 的 ResidualBlock（消融實驗 2）\n",
    "class NoShortcutBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(NoShortcutBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "# 無 BatchNorm 的 ResidualBlock（消融實驗 5）\n",
    "class NoBatchNormBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(NoBatchNormBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out += self.shortcut(identity)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "# MyNet 基礎模型\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self, num_classes=50, block=ResidualBlock, channels=64, kernel_size=7, use_maxpool=True, pool_type='avg'):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, channels, kernel_size=kernel_size, stride=2, padding=kernel_size//2, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1) if use_maxpool else nn.Identity()\n",
    "        self.block = block(channels, channels, stride=1)\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1)) if pool_type == 'avg' else nn.AdaptiveMaxPool2d((1, 1))\n",
    "        self.fc = nn.Linear(channels, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.block(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# MyNet 增加一個殞差塊（消融實驗 7）\n",
    "class MyNetExtraBlock(nn.Module):\n",
    "    def __init__(self, num_classes=50, channels=64):\n",
    "        super(MyNetExtraBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, channels, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.block1 = ResidualBlock(channels, channels, stride=1)\n",
    "        self.block2 = ResidualBlock(channels, channels, stride=1)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(channels, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# 訓練函數\n",
    "def train(model, device, train_loader, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = output.max(1)\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target).sum().item()\n",
    "    accuracy = 100. * correct / total\n",
    "    print(f'Train Epoch: {epoch}, Loss: {running_loss/len(train_loader):.4f}, Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "# 驗證函數\n",
    "def validate(model, device, val_loader, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            val_loss += criterion(output, target).item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "    accuracy = 100. * correct / total\n",
    "    print(f'Validation Loss: {val_loss/len(val_loader):.4f}, Accuracy: {accuracy:.2f}%')\n",
    "    return accuracy\n",
    "\n",
    "# 測試函數\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "    accuracy = 100. * correct / total\n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "    return accuracy\n",
    "\n",
    "# 計算 FLOPs 和參數量\n",
    "def compute_flops_params(model, input_size=(1, 3, 84, 84)):\n",
    "    model.eval()\n",
    "    input_tensor = torch.randn(input_size).to(next(model.parameters()).device)\n",
    "    flops, params = profile(model, inputs=(input_tensor,), verbose=False)\n",
    "    flops = flops / 1e9  # 轉為 GFLOPs\n",
    "    params = params / 1e6  # 轉為百萬參數\n",
    "    return flops, params\n",
    "\n",
    "# 運行單個實驗\n",
    "def run_experiment(model, device, train_loader, val_loader, test_loader, experiment_name, epochs=10):\n",
    "    print(f'\\n=== Running Experiment: {experiment_name} ===')\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    best_acc = 0.0\n",
    "    best_model_path = f'best_model_{experiment_name}.pth'\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(model, device, train_loader, optimizer, criterion, epoch)\n",
    "        val_acc = validate(model, device, val_loader, criterion)\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "    \n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    test_acc = test(model, device, test_loader)\n",
    "    flops, params = compute_flops_params(model)\n",
    "    print(f'FLOPs: {flops:.2f} GFLOPs, Parameters: {params:.2f} M')\n",
    "    return best_acc, test_acc, flops, params\n",
    "\n",
    "# 主函數：運行所有消融實驗\n",
    "def ablation_study(train_loader, val_loader, test_loader, num_classes=50, epochs=10):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    results = {}\n",
    "    \n",
    "    # 移除 Shortcut\n",
    "    model = MyNet(num_classes=num_classes, block=NoShortcutBlock).to(device)\n",
    "    val_acc, test_acc, flops, params = run_experiment(model, device, train_loader, val_loader, test_loader, 'No_Shortcut')\n",
    "    results['No_Shortcut'] = (val_acc, test_acc, flops, params)\n",
    "    \n",
    "    # 移除最大池化\n",
    "    model = MyNet(num_classes=num_classes, use_maxpool=False).to(device)\n",
    "    val_acc, test_acc, flops, params = run_experiment(model, device, train_loader, val_loader, test_loader, 'No_MaxPool')\n",
    "    results['No_MaxPool'] = (val_acc, test_acc, flops, params)\n",
    "    \n",
    "    # 移除 BatchNorm\n",
    "    model = MyNet(num_classes=num_classes, block=NoBatchNormBlock).to(device)\n",
    "    val_acc, test_acc, flops, params = run_experiment(model, device, train_loader, val_loader, test_loader, 'No_BatchNorm')\n",
    "    results['No_BatchNorm'] = (val_acc, test_acc, flops, params)\n",
    "    \n",
    "    # 增加殞差塊\n",
    "    model = MyNetExtraBlock(num_classes=num_classes).to(device)\n",
    "    val_acc, test_acc, flops, params = run_experiment(model, device, train_loader, val_loader, test_loader, 'Extra_Block')\n",
    "    results['Extra_Block'] = (val_acc, test_acc, flops, params)\n",
    "    \n",
    "    # 打印結果\n",
    "    print(\"\\n=== Ablation Study Results ===\")\n",
    "    for exp, (val_acc, test_acc, flops, params) in results.items():\n",
    "        print(f\"{exp}: Validation Accuracy = {val_acc:.2f}%, Test Accuracy = {test_acc:.2f}%, FLOPs = {flops:.2f} GFLOPs, Parameters = {params:.2f} M\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 假設 train_loader, val_loader, test_loader 已定義\n",
    "    ablation_study(train_loader, val_loader, test_loader, num_classes=50, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

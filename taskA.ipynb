{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da193020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# 解壓 images.zip\n",
    "def unzip_dataset(zip_path, extract_path):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_path)\n",
    "    print(f\"Extracted {zip_path} to {extract_path}\")\n",
    "\n",
    "# 假設 images.zip 在當前目錄\n",
    "zip_path = \"images.zip\"\n",
    "extract_path = \"dataset\"\n",
    "if not os.path.exists(extract_path):\n",
    "    unzip_dataset(zip_path, extract_path)\n",
    "\n",
    "# 自定義數據集類\n",
    "class MiniImageNetDataset(Dataset):\n",
    "    def __init__(self, txt_file, root_dir, channels, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.channels = channels  # 控制輸入通道：RGB, RG, R, G, B 等\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # 讀取 txt 文件\n",
    "        with open(txt_file, 'r') as f:\n",
    "            for line in f:\n",
    "                img_path, label = line.strip().split()\n",
    "                self.data.append(img_path)\n",
    "                self.labels.append(int(label))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, self.data[idx])\n",
    "        image = Image.open(img_path).convert(\"RGB\")  # 默認加載為 RGB\n",
    "        \n",
    "        # 根據 channels 選擇通道\n",
    "        img_array = np.array(image)        \n",
    "        image = Image.fromarray(img_array)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "def get_transform(channels):\n",
    "    if channels == \"R\":\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((84, 84)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda x: x[0:1, :, :]),  \n",
    "            transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "        ])\n",
    "    elif channels == \"G\":\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((84, 84)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda x: x[1:2, :, :]),\n",
    "            transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "        ])\n",
    "    elif channels == \"B\":\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((84, 84)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda x: x[2:3, :, :]), \n",
    "            transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "        ])\n",
    "    elif channels == \"RG\":\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((84, 84)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda x: x[:2, :, :]),\n",
    "            transforms.Normalize(mean=[0.485, 0.456], std=[0.229, 0.224])\n",
    "        ])\n",
    "    else:  # RGB\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((84, 84)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247fb8a5",
   "metadata": {},
   "source": [
    "## SimpleCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a234869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple CNN\n",
    "import torch.nn.functional as F\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes=10, input_size=84):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        \n",
    "        # 計算池化後的空間維度\n",
    "        spatial_size = input_size // 4  # 經過兩次池化，每次減半\n",
    "        self.fc1 = nn.Linear(32 * spatial_size * spatial_size, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd80e44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 函數：將圖像轉換為指定通道數量\n",
    "def convert_channels(images, target_channels):\n",
    "    if target_channels == 3:\n",
    "        return images\n",
    "    elif target_channels == 2:\n",
    "        return images[:, :2, :, :]\n",
    "    elif target_channels == 1:\n",
    "        return images[:, :1, :, :]\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported target channels: {target_channels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716a815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test\n",
    "def train_model(model, train_loader, val_loader, target_channels, num_epochs=10, device='cuda'):\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            # 根據 target_channels 轉換圖像通道數量\n",
    "            images = convert_channels(images, target_channels)\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = 100 * correct / total\n",
    "\n",
    "        # 驗證階段\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = convert_channels(images, target_channels)\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_acc = 100 * correct / total\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}] | '\n",
    "              f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "    return model\n",
    "\n",
    "# 測試函數\n",
    "def test_model(model, test_loader, target_channels, device='cuda'):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0.0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = convert_channels(images, target_channels)\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_loss = test_loss / len(test_loader)\n",
    "    test_acc = 100 * correct / total\n",
    "    print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%')\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a9d2aa",
   "metadata": {},
   "source": [
    "#### RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5cc870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建數據集\n",
    "train_dataset_rgb = MiniImageNetDataset(\n",
    "    txt_file=os.path.join(extract_path, \"train.txt\"),\n",
    "    root_dir=extract_path,\n",
    "    transform=get_transform(\"RGB\"),\n",
    "    channels=\"RGB\"\n",
    ")\n",
    "val_dataset_rgb = MiniImageNetDataset(\n",
    "    txt_file=os.path.join(extract_path, \"val.txt\"),\n",
    "    root_dir=extract_path,\n",
    "    transform=get_transform(\"RGB\"),\n",
    "    channels=\"RGB\"\n",
    ")\n",
    "test_dataset_rgb = MiniImageNetDataset(\n",
    "    txt_file=os.path.join(extract_path, \"test.txt\"),\n",
    "    root_dir=extract_path,\n",
    "    transform=get_transform(\"RGB\"),\n",
    "    channels=\"RGB\"\n",
    ")\n",
    "\n",
    "train_rgb_loader = DataLoader(train_dataset_rgb, batch_size=64, shuffle=True)\n",
    "val_rgb_loader = DataLoader(val_dataset_rgb, batch_size=64, shuffle=True)\n",
    "test_rgb_loader = DataLoader(test_dataset_rgb, batch_size=64, shuffle=True)\n",
    "\n",
    "for images, labels in train_rgb_loader:\n",
    "    print(\"Image shape:\", images.shape) \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cdcb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_classes = 50\n",
    "num_epochs = 10\n",
    "input_size = 84  # 根據實際圖像大小設置\n",
    "\n",
    "# 訓練和測試 3 通道 (RGB)\n",
    "print(\"Training and Testing SimpleCNN with 3 channels (RGB)...\")\n",
    "model_rgb = SimpleCNN(in_channels=3, num_classes=num_classes, input_size=input_size)\n",
    "model_rgb = train_model(model_rgb, train_rgb_loader, val_rgb_loader, target_channels=3, num_epochs=num_epochs, device=device)\n",
    "test_acc_rgb = test_model(model_rgb, test_rgb_loader, target_channels=3, device=device)\n",
    "\n",
    "print(\"\\nSummary of Test Accuracies:\")\n",
    "print(f\"SimpleCNN (3 channels - RGB): {test_acc_rgb:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e086e0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "# 模型參數量\n",
    "summary(model_rgb, (3, 84, 84))  # 假設輸入是 RGB 圖像\n",
    "\n",
    "# 如果需要計算 FLOPS，可以使用 ptflops\n",
    "try:\n",
    "    from ptflops import get_model_complexity_info\n",
    "    flops, params = get_model_complexity_info(model_rgb, (3, 84, 84), as_strings=True, print_per_layer_stat=False)\n",
    "    print(f\"Computational complexity: {flops}\")\n",
    "    print(f\"Number of parameters: {params}\")\n",
    "except ImportError:\n",
    "    print(\"Please install ptflops to compute FLOPS: pip install ptflops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6dc62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_rgb.state_dict(), 'model_rgb_state_dict.pth')\n",
    "del train_dataset_rgb\n",
    "del train_rgb_loader\n",
    "del val_dataset_rgb\n",
    "del val_rgb_loader\n",
    "del test_dataset_rgb\n",
    "del test_rgb_loader\n",
    "del model_rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c496348",
   "metadata": {},
   "source": [
    "#### RG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e25a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建數據集\n",
    "train_dataset_rg = MiniImageNetDataset(\n",
    "    txt_file=os.path.join(extract_path, \"train.txt\"),\n",
    "    root_dir=extract_path,\n",
    "    transform=get_transform(\"RG\"),\n",
    "    channels=\"RG\"\n",
    ")\n",
    "val_dataset_rg = MiniImageNetDataset(\n",
    "    txt_file=os.path.join(extract_path, \"val.txt\"),\n",
    "    root_dir=extract_path,\n",
    "    transform=get_transform(\"RG\"),\n",
    "    channels=\"RG\"\n",
    ")\n",
    "test_dataset_rg = MiniImageNetDataset(\n",
    "    txt_file=os.path.join(extract_path, \"test.txt\"),\n",
    "    root_dir=extract_path,\n",
    "    transform=get_transform(\"RG\"),\n",
    "    channels=\"RG\"\n",
    ")\n",
    "\n",
    "train_rg_loader = DataLoader(train_dataset_rg, batch_size=64, shuffle=True)\n",
    "val_rg_loader = DataLoader(val_dataset_rg, batch_size=64, shuffle=True)\n",
    "test_rg_loader = DataLoader(test_dataset_rg, batch_size=64, shuffle=True)\n",
    "\n",
    "for images, labels in train_rg_loader:\n",
    "    print(\"Image shape:\", images.shape) \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62e06c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_classes = 50\n",
    "num_epochs = 10\n",
    "input_size = 84  # 根據實際圖像大小設置\n",
    "\n",
    "# 訓練和測試\n",
    "print(\"Training and Testing SimpleCNN with  channels (RG)...\")\n",
    "model_rg = SimpleCNN(in_channels=2, num_classes=num_classes, input_size=input_size)\n",
    "model_rg = train_model(model_rg, train_rg_loader, val_rg_loader, target_channels=2, num_epochs=num_epochs, device=device)\n",
    "test_acc_rg = test_model(model_rg, test_rg_loader, target_channels=2, device=device)\n",
    "\n",
    "print(\"\\nSummary of Test Accuracies:\")\n",
    "print(f\"SimpleCNN (3 channels - RGB): {test_acc_rg:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be52ca33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "# 模型參數量\n",
    "summary(model_rg, (2, 84, 84)) \n",
    "\n",
    "# 如果需要計算 FLOPS，可以使用 ptflops\n",
    "try:\n",
    "    from ptflops import get_model_complexity_info\n",
    "    flops, params = get_model_complexity_info(model_rg, (2, 84, 84), as_strings=True, print_per_layer_stat=False)\n",
    "    print(f\"Computational complexity: {flops}\")\n",
    "    print(f\"Number of parameters: {params}\")\n",
    "except ImportError:\n",
    "    print(\"Please install ptflops to compute FLOPS: pip install ptflops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2bf14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_rg.state_dict(), 'model_rg_state_dict.pth')\n",
    "del train_dataset_rg\n",
    "del train_rg_loader\n",
    "del val_dataset_rg\n",
    "del val_rg_loader\n",
    "del test_dataset_rg\n",
    "del test_rg_loader\n",
    "del model_rg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05257771",
   "metadata": {},
   "source": [
    "#### R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3a0771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建數據集\n",
    "train_dataset_r = MiniImageNetDataset(\n",
    "    txt_file=os.path.join(extract_path, \"train.txt\"),\n",
    "    root_dir=extract_path,\n",
    "    transform=get_transform(\"R\"),\n",
    "    channels=\"R\"\n",
    ")\n",
    "val_dataset_r = MiniImageNetDataset(\n",
    "    txt_file=os.path.join(extract_path, \"val.txt\"),\n",
    "    root_dir=extract_path,\n",
    "    transform=get_transform(\"R\"),\n",
    "    channels=\"R\"\n",
    ")\n",
    "test_dataset_r = MiniImageNetDataset(\n",
    "    txt_file=os.path.join(extract_path, \"test.txt\"),\n",
    "    root_dir=extract_path,\n",
    "    transform=get_transform(\"R\"),\n",
    "    channels=\"R\"\n",
    ")\n",
    "\n",
    "train_r_loader = DataLoader(train_dataset_r, batch_size=64, shuffle=True)\n",
    "val_r_loader = DataLoader(val_dataset_r, batch_size=64, shuffle=True)\n",
    "test_r_loader = DataLoader(test_dataset_r, batch_size=64, shuffle=True)\n",
    "\n",
    "for images, labels in train_r_loader:\n",
    "    print(\"Image shape:\", images.shape) \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2c42a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_classes = 50\n",
    "num_epochs = 10\n",
    "input_size = 84  # 根據實際圖像大小設置\n",
    "\n",
    "# 訓練和測試\n",
    "print(\"Training and Testing SimpleCNN with  channels (R)...\")\n",
    "model_r = SimpleCNN(in_channels=1, num_classes=num_classes, input_size=input_size)\n",
    "model_r = train_model(model_r, train_r_loader, val_r_loader, target_channels=1, num_epochs=num_epochs, device=device)\n",
    "test_acc_r = test_model(model_r, test_r_loader, target_channels=1, device=device)\n",
    "\n",
    "print(\"\\nSummary of Test Accuracies:\")\n",
    "print(f\"SimpleCNN (3 channels - RGB): {test_acc_r:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37413b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "# 模型參數量\n",
    "summary(model_r, (1, 84, 84)) \n",
    "\n",
    "# 如果需要計算 FLOPS，可以使用 ptflops\n",
    "try:\n",
    "    from ptflops import get_model_complexity_info\n",
    "    flops, params = get_model_complexity_info(model_r, (1, 84, 84), as_strings=True, print_per_layer_stat=False)\n",
    "    print(f\"Computational complexity: {flops}\")\n",
    "    print(f\"Number of parameters: {params}\")\n",
    "except ImportError:\n",
    "    print(\"Please install ptflops to compute FLOPS: pip install ptflops\")\n",
    "torch.save(model_r.state_dict(), 'model_r_state_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342ad6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_dataset_r\n",
    "del train_r_loader\n",
    "del val_dataset_r\n",
    "del val_r_loader\n",
    "del test_dataset_r\n",
    "del test_r_loader\n",
    "del model_r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86f6d7b",
   "metadata": {},
   "source": [
    "## DynamicConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39444adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DynamicConv(nn.Module):\n",
    "    def __init__(self, max_in_channels, out_channels, kernel_size=3, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.max_in_channels = max_in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        # 動態 kernel 生成器：輸入通道數 (one-hot)，輸出一組 kernel\n",
    "        self.kernel_generator = nn.Sequential(\n",
    "            nn.Linear(max_in_channels, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, out_channels * max_in_channels * kernel_size * kernel_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, in_c, h, w = x.shape\n",
    "\n",
    "        # 建立 one-hot 向量，代表目前的輸入通道數\n",
    "        channel_mask = torch.zeros(self.max_in_channels, device=x.device)\n",
    "        channel_mask[:in_c] = 1\n",
    "\n",
    "        # 產生 kernel，reshape 成 conv2d 欲用格式\n",
    "        kernels = self.kernel_generator(channel_mask)\n",
    "        kernels = kernels.view(self.out_channels, self.max_in_channels, self.kernel_size, self.kernel_size)\n",
    "        \n",
    "        # 只取前 in_c 個通道\n",
    "        kernels = kernels[:, :in_c, :, :]\n",
    "\n",
    "        # 用 F.conv2d 做卷積\n",
    "        out = F.conv2d(x, kernels, bias=None, padding=self.kernel_size//2)\n",
    "        return out\n",
    "class DynamicCNN(nn.Module):\n",
    "    def __init__(self, max_in_channels=3, num_classes=100):\n",
    "        super().__init__()\n",
    "        self.dynamic_conv = DynamicConv(max_in_channels=max_in_channels, out_channels=32, kernel_size=3)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.dynamic_conv(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.global_pool(x).view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1c90c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "class DynamicTransformWrapper:\n",
    "    def __init__(self):\n",
    "        self.channel_options = [\"RGB\", \"RG\", \"R\"]\n",
    "    \n",
    "    def __call__(self, image):\n",
    "        channels = random.choice(self.channel_options)\n",
    "        transform = get_transform(channels)\n",
    "        return transform(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53db8b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset/val.txt\", 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "random.shuffle(lines)\n",
    "\n",
    "channel_options = [\"RGB\",\"RG\",\"R\"]\n",
    "n = len(lines)\n",
    "n_per_channel = n // len(channel_options)\n",
    "channel_lines = {ch: [] for ch in channel_options}\n",
    "    \n",
    "# Assign lines to channels\n",
    "for i, line in enumerate(lines):\n",
    "    if i < n_per_channel:\n",
    "        channel_lines[\"RGB\"].append(line)\n",
    "    elif i < 2 * n_per_channel:\n",
    "        channel_lines[\"RG\"].append(line)\n",
    "    else:\n",
    "        channel_lines[\"R\"].append(line)\n",
    "    \n",
    "# Write to separate text files\n",
    "for channel in channel_options:\n",
    "    output_file = os.path.join(\"dataset\",f\"val_{channel.lower()}.txt\")\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.writelines(channel_lines[channel])\n",
    "    print(f\"Generated {output_file} with {len(channel_lines[channel])} images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdc99e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 動態模型的數據集（RGB、RG、R）\n",
    "train_dataset_rgb = MiniImageNetDataset(\n",
    "    txt_file=os.path.join(extract_path, \"train_rgb.txt\"),\n",
    "    root_dir=extract_path,\n",
    "    transform=get_transform(\"RGB\"),\n",
    "    channels=\"RGB\"\n",
    ")\n",
    "train_dataset_rg = MiniImageNetDataset(\n",
    "    txt_file=os.path.join(extract_path, \"train_rg.txt\"),\n",
    "    root_dir=extract_path,\n",
    "    transform=get_transform(\"RG\"),\n",
    "    channels=\"RG\"\n",
    ")\n",
    "train_dataset_r = MiniImageNetDataset(\n",
    "    txt_file=os.path.join(extract_path, \"train_r.txt\"),\n",
    "    root_dir=extract_path,\n",
    "    transform=get_transform(\"R\"),\n",
    "    channels=\"R\"\n",
    ")\n",
    "\n",
    "# Create separate DataLoaders\n",
    "train_loader_rgb = DataLoader(train_dataset_rgb, batch_size=64, shuffle=True)\n",
    "train_loader_rg = DataLoader(train_dataset_rg, batch_size=64, shuffle=True)\n",
    "train_loader_r = DataLoader(train_dataset_r, batch_size=64, shuffle=True)\n",
    "\n",
    "val_dataset_rgb = MiniImageNetDataset(\n",
    "    txt_file=os.path.join(extract_path, \"val_rgb.txt\"),\n",
    "    root_dir=extract_path,\n",
    "    transform=get_transform(\"RGB\"),\n",
    "    channels=\"RGB\"\n",
    ")\n",
    "val_dataset_rg = MiniImageNetDataset(\n",
    "    txt_file=os.path.join(extract_path, \"val_rg.txt\"),\n",
    "    root_dir=extract_path,\n",
    "    transform=get_transform(\"RG\"),\n",
    "    channels=\"RG\"\n",
    ")\n",
    "val_dataset_r = MiniImageNetDataset(\n",
    "    txt_file=os.path.join(extract_path, \"val_r.txt\"),\n",
    "    root_dir=extract_path,\n",
    "    transform=get_transform(\"R\"),\n",
    "    channels=\"R\"\n",
    ")\n",
    "\n",
    "# Create separate DataLoaders\n",
    "val_loader_rgb = DataLoader(val_dataset_rgb, batch_size=64, shuffle=True)\n",
    "val_loader_rg = DataLoader(val_dataset_rg, batch_size=64, shuffle=True)\n",
    "val_loader_r = DataLoader(val_dataset_r, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "# 測試數據集（分為 RGB、RG、R 三組）\n",
    "test_dataset_rgb = MiniImageNetDataset(\n",
    "    txt_file=os.path.join(extract_path, \"test.txt\"),\n",
    "    root_dir=extract_path,\n",
    "    transform=get_transform(\"RGB\"),\n",
    "    channels=\"RGB\"\n",
    ")\n",
    "test_loader_rgb = DataLoader(test_dataset_rgb, batch_size=64, shuffle=False)\n",
    "\n",
    "test_dataset_rg = MiniImageNetDataset(\n",
    "    txt_file=os.path.join(extract_path, \"test.txt\"),\n",
    "    root_dir=extract_path,\n",
    "    transform=get_transform(\"RG\"),\n",
    "    channels=\"RG\"\n",
    ")\n",
    "test_loader_rg = DataLoader(test_dataset_rg, batch_size=64, shuffle=False)\n",
    "\n",
    "test_dataset_r = MiniImageNetDataset(\n",
    "    txt_file=os.path.join(extract_path, \"test.txt\"),\n",
    "    root_dir=extract_path,\n",
    "    transform=get_transform(\"R\"),\n",
    "    channels=\"R\"\n",
    ")\n",
    "test_loader_r = DataLoader(test_dataset_r, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd9b30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loaders, val_loaders, criterion, optimizer, num_epochs, device):\n",
    "    best_val_acc = 0.0\n",
    "    epochs_no_improve = 0\n",
    "    patience = 5  # 假設早停耐心值為 5\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # 訓練階段\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        train_preds = []\n",
    "        train_labels = []\n",
    "\n",
    "        # 迭代每個訓練 DataLoader（RGB, RG, R）\n",
    "        for train_loader in train_loaders:\n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                # 前向傳播\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # 反向傳播和優化\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                train_preds.extend(predicted.cpu().numpy())\n",
    "                train_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        train_accuracy = accuracy_score(train_labels, train_preds)\n",
    "        avg_train_loss = running_loss / sum(len(loader) for loader in train_loaders)\n",
    "\n",
    "        # 驗證階段\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            # 迭代每個驗證 DataLoader（RGB, RG, R）\n",
    "            for val_loader in val_loaders:\n",
    "                for images, labels in val_loader:\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    val_loss += loss.item()\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    all_preds.extend(predicted.cpu().numpy())\n",
    "                    all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_accuracy = accuracy_score(all_labels, all_preds)\n",
    "        avg_val_loss = val_loss / sum(len(loader) for loader in val_loaders)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "        print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "        \n",
    "        # 早停機制\n",
    "        if val_accuracy > best_val_acc:\n",
    "            best_val_acc = val_accuracy\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), \"best_model_dynamic.pth\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(\"早停觸發！\")\n",
    "                break\n",
    "        \n",
    "        model.train()\n",
    "    return model\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "def test_model(model, test_loader, channel_combination, device):\n",
    "    model.eval()\n",
    "    print(f\"\\nTesting with channel combination: {channel_combination}\")\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    print(f\"Accuracy for {channel_combination}: {accuracy * 100:.2f}%\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_labels, all_preds))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06bbe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_classes = 50\n",
    "num_epochs = 10\n",
    "\n",
    "# Define channel combinations to test\n",
    "channel_combinations = [\"RGB\", \"RG\", \"R\"]\n",
    "\n",
    "# Initialize model, criterion, and optimizer\n",
    "model = DynamicCNN(num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_loaders = [train_loader_rgb, train_loader_rg, train_loader_r]\n",
    "val_loaders = [val_loader_rgb, val_loader_rg, val_loader_r]\n",
    "model_dynamic = train_model(model, train_loaders, val_loaders, criterion, optimizer, num_epochs, device)\n",
    "torch.save(model_dynamic.state_dict(), 'model_state_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93838d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "# 模型參數量\n",
    "summary(model, (2, 84, 84)) \n",
    "\n",
    "# 如果需要計算 FLOPS，可以使用 ptflops\n",
    "try:\n",
    "    from ptflops import get_model_complexity_info\n",
    "    flops, params = get_model_complexity_info(model, (3, 84, 84), as_strings=True, print_per_layer_stat=False)\n",
    "    print(f\"Computational complexity: {flops}\")\n",
    "    print(f\"Number of parameters: {params}\")\n",
    "except ImportError:\n",
    "    print(\"Please install ptflops to compute FLOPS: pip install ptflops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fee5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Phase: Test on each channel combination\n",
    "print(\"\\n=== Testing Phase ===\")\n",
    "results = {}\n",
    "for channel_combination in channel_combinations:\n",
    "    print(f\"\\nTesting on {channel_combination} data...\")\n",
    "    \n",
    "    # Create test dataset for the current channel combination\n",
    "    test_dataset = MiniImageNetDataset(\n",
    "        txt_file=os.path.join(extract_path, \"test.txt\"),\n",
    "        root_dir=extract_path,\n",
    "        transform=get_transform(channel_combination),\n",
    "        channels=channel_combination\n",
    "    )\n",
    "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "    \n",
    "    # Test the model on this channel combination\n",
    "    accuracy = test_model(model, test_loader, channel_combination, device)\n",
    "    results[channel_combination] = accuracy\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nSummary of Test Accuracies:\")\n",
    "for channel_combination, accuracy in results.items():\n",
    "    print(f\"{channel_combination}: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
